Whisper는 OpenAI에서 개발한 자동 음성 인식(ASR, Automatic Speech Recognition) 모델로, 음성을 텍스트로 변환하는 기능을 수행합니다. 2022년 9월에 오픈소스로 공개되었으며, 다양한 언어와 방언을 인식하고 처리하는 데 강점을 가지고 있습니다.
 
    
        주요 특징
    
    
다국어 지원: 99개 이상의 언어를 인식하고, 일부 언어의 경우 영어로 번역하는 기능도 지원합니다.
높은 정확도: 방대한 양의 데이터(680,000시간)를 학습하여 억양, 배경 소음, 전문 용어 등 다양한 환경에서도 높은 정확도를 보입니다. 특히 영어 인식에서 인간 수준에 근접하는 성능을 나타냅니다.
멀티태스킹: 단순한 음성-텍스트 변환(Transcription) 외에도 번역(Translation), 언어 식별(Language Identification), 음성 활동 감지(Voice Activity Detection) 등 다양한 작업을 하나의 모델로 수행할 수 있습니다.
Weak Supervision 학습: 레이블이 없는 대규모 데이터셋을 활용하는 Weakly-supervised Learning 방식을 사용하여, 특정 데이터셋에 대한 추가적인 파인튜닝 없이도 뛰어난 일반화 성능을 보여줍니다.
오픈소스: GitHub를 통해 모델과 추론 코드가 공개되어 있어 누구나 자유롭게 활용하고 개발에 적용할 수 있습니다.
다양한 모델 크기: Tiny, Base, Small, Medium, Large 등 다양한 크기의 모델을 제공하여, 사용자의 하드웨어 사양이나 목적에 맞게 선택하여 사용할 수 있습니다. 모델 크기가 클수록 정확도가 높아지지만 처리 속도와 메모리 사용량은 증가합니다.

 
    
        한국어 성능
    
    Whisper는 한국어 데이터 약 8,000시간을 포함하여 학습되었으며, 영어 외 언어 중 7번째로 많은 데이터를 학습했습니다. 이를 통해 한국어 음성 인식에서도 높은 성능을 보여주며, 일부 연구에서는 기존 STT 시스템과 유사하거나 더 나은 결과를 나타내기도 합니다.
 
    
        파인튜닝 (Fine-tuning)
    
    Whisper 모델은 특정 도메인이나 작업에 맞게 성능을 개선하기 위해 파인튜닝될 수 있습니다. 예를 들어, 구음 장애 환자 데이터나 특정 환경의 음성 데이터를 활용하여 한국어 음성 인식 모델의 정확도를 높이는 연구가 진행되었습니다.
 
    
        활용 사례
    
    
자동 자막 생성: 유튜브, 팟캐스트, 강의 등의 오디오 콘텐츠 자막 생성에 활용됩니다.
음성 비서 및 챗봇: AI 음성 인터페이스 및 음성 명령 처리에 사용될 수 있습니다.
회의록 작성: 회의나 인터뷰 내용을 자동으로 텍스트로 기록하여 문서화하는 데 활용됩니다.
의료 분야: 응급실 진료 대화 음성 인식 및 진료 프로세스 분류 등 의료 분야에도 적용될 수 있습니다.
기타: 음성 명령 기반 제어, 오디오 콘텐츠 검색 등 다양한 응용 분야에 활용 가능합니다.

 
    
        모델 종류 및 다운로드
    
    Whisper 모델은 크기에 따라 다양한 버전이 있으며, Hugging Face나 GitHub를 통해 모델 가중치 및 관련 코드를 다운로드하여 사용할 수 있습니다. PotPlayer와 같은 특정 프로그램에서는 엔진 및 모델 파일을 수동으로 추가하는 방법도 제공됩니다.
 
    
        장단점 및 한계
    
    장점:

높은 정확도와 다양한 언어 지원
멀티태스킹 기능 및 Zero-shot 학습 능력
오픈소스 및 쉬운 사용법
노이즈에 강건한 성능

단점 및 한계:

'환각(Hallucination)' 현상: 오디오에 존재하지 않는 텍스트를 생성하는 경우가 있습니다.
언어별 성능 편차: 한국어 등 일부 언어에서는 영어에 비해 정확도가 다소 떨어질 수 있습니다.
반복적인 텍스트 생성: 간혹 같은 출력을 반복하는 문제가 발생할 수 있습니다.
모델 크기에 따른 성능 및 리소스 요구사항 차이: Large 모델은 높은 정확도를 제공하지만, 더 많은 컴퓨팅 자원을 요구합니다.
파인튜닝 시 데이터셋의 중요성: 특정 도메인에 최적화된 성능을 위해서는 고품질의 파인튜닝 데이터가 필요합니다.
띄어쓰기 및 문장 부호 처리: 한국어의 경우 띄어쓰기 오류나 문장 부호 자동 삽입 기능이 부족할 수 있어 후처리 과정이 필요할 수 있습니다.


모델 파악
링크 : https://turingpost.co.kr/p/topic-15-openai-whisper

모델 사용법
링크 : https://www.magicaiprompts.com/docs/gpt-chatbot/whisper-speech-recognition-api/

파인튜닝
링크 : https://ysg2997.tistory.com/53

양자화
링크 : https://medium.com/@daniel-klitzke/quantizing-openais-whisper-with-the-huggingface-optimum-library-30-faster-inference-64-36d9815190e0


양자화 비교
링크 : https://www.chatpaper.ai/ko/dashboard/paper/3074c9d4-da0c-4444-85b2-23949f26829c


Whisper 모델 양자화 방법 및 효과
    
    Whisper 모델의 양자화는 모델의 효율성을 높이는 데 기여하며, 다양한 라이브러리와 기법을 통해 구현될 수 있습니다.

    
        주요 양자화 라이브러리 및 기법
    
    
Huggingface Optimum 및 CTranslate2: Huggingface의 Optimum 라이브러리와 CTranslate2를 사용하여 Whisper 모델을 ONNX 형식으로 내보내고 양자화할 수 있습니다. 이를 통해 추론 시간을 30% 이상 단축하고 메모리 사용량을 64% 줄일 수 있습니다. CTranslate2는 INT8, INT16, FP16 등의 양자화를 지원하며, 모델 변환 시 또는 모델 로딩 시에 양자화를 적용할 수 있습니다.
bitsandbytes: Huggingface Transformers 라이브러리는 bitsandbytes를 통해 8비트 및 4비트 양자화를 지원합니다.
GPTQ: Generative Pre-trained Transformer 모델을 위한 정확하고 효율적인 후처리 양자화 기법으로, 3~4비트까지 양자화하면서도 정확도 손실을 최소화합니다.
AWQ (Asymmetric Weight Quantization): 활성화 값을 고려하여 가중치를 비대칭적으로 양자화하는 방법입니다.
GGML/GGUF: whisper.cpp와 같은 프로젝트에서 GGML 형식(GGUF는 GGML의 개선된 형식)을 사용하여 Whisper 모델을 양자화합니다. 이를 통해 디스크 크기와 메모리 사용량을 줄이고 일부 아키텍처에서는 추론 속도를 향상시킬 수 있습니다.
Quanto: Huggingface의 Quanto 라이브러리를 사용하여 PyTorch 모델을 양자화할 수 있으며, quantize() 및 freeze() 함수를 통해 가중치를 INT8과 같은 낮은 비트로 양자화할 수 있습니다.
HQQ: Hugging Face의 HQQ 라이브러리를 사용하여 Whisper 모델을 양자화하는 연구도 진행되었습니다.

 
    
        양자화의 효과
    
    
모델 크기 감소: 양자화를 통해 모델의 저장 공간 요구 사항을 크게 줄일 수 있습니다. 예를 들어, INT4, INT5, INT8 양자화를 통해 모델 크기를 45%까지 감소시킬 수 있습니다.
추론 속도 향상: 낮은 정밀도의 연산은 일반적으로 더 빠르므로, 양자화는 추론 지연 시간을 줄여줍니다. INT8 양자화를 통해 지연 시간을 19%까지 줄일 수 있다는 연구 결과도 있습니다.
메모리 사용량 감소: 모델 크기 감소는 곧 메모리 사용량 감소로 이어져, 리소스가 제한된 환경에서의 모델 배포를 용이하게 합니다.
정확도 유지: 효과적인 양자화 기법은 모델의 정확도 저하를 최소화하거나 거의 없도록 합니다.

 
    
        양자화 시 고려사항
    
    
정확도와 효율성 간의 트레이드오프: 양자화는 모델의 효율성을 높이지만, 과도한 양자화는 모델 성능 저하나 환각 현상(hallucination)을 유발할 수 있습니다.
하드웨어 지원: 양자화된 모델의 성능은 하드웨어의 지원 여부에 따라 달라질 수 있습니다. AMD, ARM CPU, Apple Silicon, NVIDIA GPU 등은 양자화 연산에 대한 지원을 강화하고 있습니다.
양자화 방식 선택: 모델의 용도, 하드웨어 환경, 요구되는 정확도 수준 등을 고려하여 최적의 양자화 기법(예: GPTQ, AWQ, INT8, INT4 등)을 선택하는 것이 중요합니다.

 
    
        Whisper 모델의 양자화 사례
    
    
whisper.cpp: C++로 구현된 Whisper 모델은 GGML 형식과 함께 정수형 양자화(INT4, INT6, INT8)를 지원하여 디스크 크기 및 메모리 사용량을 줄이고 추론 속도를 향상시킵니다.
Enerzai: Enerzai는 Optimium 엔진과 1.58비트 양자화된 Whisper Small 모델을 Arm 기반 SoC에서 구동하는 기술을 개발했습니다.
RedHatAI: Hugging Face에 whisper-large-v2-quantized.w4a16과 같이 INT4 데이터 타입으로 양자화된 Whisper 모델이 공개되어 있습니다.
BC카드: BC카드는 양자화된 초거대 언어 모델 18종을 허깅페이스에 공개했으며, 이는 고가의 GPU 없이도 AI 활용을 가능하게 합니다.